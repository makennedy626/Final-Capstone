{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Read 6.1 Time Series and 6.4 Advanced NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "##### Abstract will be written after all analyses are complete.\n",
    "\n",
    "For a copy of the proposal, visit https://github.com/makennedy626/Final-Capstone/blob/master/Final%20Capstone%20Project%20Proposal.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### I. Objective\n",
    "\n",
    "### II. Data Access and Overview\n",
    "\n",
    "### III. Scraping Google News API for Investor Sentiment\n",
    "\n",
    "### IV. Unsupervised Machine Learning on Scraped Data to Generate Sentiment Analysis\n",
    "\n",
    "### V. Supervised Machine Learning to Generate Prediction Models\n",
    "\n",
    "### VI. Unsupervised Neural Networks on Scraped Data to Generate Sentiment Analysis\n",
    "\n",
    "### VII. Supervised Neural Networks to Generate Prediction Models\n",
    "\n",
    "### VIII. Performance Comparison of Techniques\n",
    "\n",
    "### IX. Creating an Ensemble Model of the Highest Peforming Components of the Techniques\n",
    "\n",
    "### X. Results of the Ensemble Model\n",
    "\n",
    "### XI. Conclusion\n",
    "\n",
    "### XII. Important Information from Quantopian's Contest Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Objective\n",
    "\n",
    "The objective of this project is to create a profitable algorithm leveraging Quantopian's investment platform. The platform provides users with an integrated Python environment from which the user may backtest the algorithm(s) on historical stock prices. Quantopian also provides many free and paid-for data sets and built in functions. \n",
    "\n",
    "The end goal is to have a solution that will generate positive gains over time in the stock market while meeting Quantopian's Contest Criteria. For an overview of the contest rules and judging criteria, see XII. Importan Information from Quantopian's Contest Page.\n",
    "\n",
    "If the criteria are met, the algorithm is evaluated for the possibility for licensing to Quantopian. If licensed, capital is allocated (starting allocations average approximately five million dollars per alogrithm), and the author receives ten percent of the net profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Access and Overview\n",
    "\n",
    "The project will utilize Quantopian's provided open-sourced backtesting engine (Zipline) and free data sources from Quantopian (provided by Morningstar), which consists of over 600 metrics measuring the financial performance of companies and is derived from their public filings. The data is split- and dividend-adjusted.\n",
    "\n",
    "Quantopian algorithms utilize \"universes\" that are collections of approved stocks (based upon metrics outlined below) and are generated by Quantopian and frequently updated. \n",
    "\n",
    "The data will be accessed using Quantopian's Pipeline API.\n",
    "\n",
    "## II.I Information About the QTradableStocksUS Universe from Quantopian\n",
    "*Taken from Quantopian's page, https://www.quantopian.com/posts/working-on-our-best-universe-yet-qtradablestocksus, where the advantages of this new universe over the previous (Q500US and Q1500US) are discussed.\n",
    "\n",
    "QTradableStocksUS has no explicit size limit, and generally has between 1600-2100 members.\n",
    "\n",
    "The new universe has more effective screens to remove illiquid or otherwise untradeable stocks.\n",
    "\n",
    "For companies with more than one share class, the new universe picks the most liquid rather than always picking the primary share.\n",
    "\n",
    "The new universe is updated daily rather than monthly.\n",
    "\n",
    "Here are the specific limits applied to the QTradableStocksUS:\n",
    "\n",
    "Market cap:  over \\$500M: This restriction eliminates many undiversifiable risks like low liquidity and difficulty in shorting.\n",
    "\n",
    "Dollar volume: It is important that stocks in our universe be relatively easy to trade when entering and exiting positions. The QTradableStocksUS manages that by including only stocks that have median daily dollar volume of $2.5m or more over the trailing 200 days.\n",
    "\n",
    "Prior day's close: If a stock's price is lower than \\$5, the bid-ask spread becomes larger relative to the price, and the transaction cost becomes too high.\n",
    "\n",
    "\\200 days of price and volume: If a stock has missing data for the previous 200 days, the company is excluded. This targets stocks with trading halts, IPOs, and other situations that make them harder to assess.\n",
    "\n",
    "Primary/Common share: The QTradableStocksUS chooses a single share class for each company. The criteria is to find the common share with the most dollar volume.\n",
    "\n",
    "ADRs, Limited Partnerships: QTradableStocksUS excludes ADRs and LPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.II Visualizing QTradableStocksUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quantopian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d56c727f50a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mquantopian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFundamentals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquantopian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmorningstar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquantopian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAverageDollarVolume\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquantopian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorningstar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMarketCap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquantopian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorningstar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quantopian'"
     ]
    }
   ],
   "source": [
    "from quantopian.pipeline.data import Fundamentals\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.pipeline.factors import AverageDollarVolume\n",
    "from quantopian.pipeline.factors.morningstar import MarketCap\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.research import run_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import time\n",
    "\n",
    "from quantopian.pipeline.experimental import QTradableStocksUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function used to create a pipeline with the QTradableStocksUS as a screen. The pipeline contains common metrics as columns:\n",
    "def make_pipeline():\n",
    "    \n",
    "    average_day_dv_200 = AverageDollarVolume(window_length=200)\n",
    "    market_cap = Fundamentals.market_cap.latest\n",
    "    price = USEquityPricing.close.latest\n",
    "    volume = USEquityPricing.volume.latest\n",
    "    sector = Sector()\n",
    "\n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'AverageDollarVolume200': average_day_dv_200,\n",
    "            'MarketCap': market_cap,\n",
    "            'Price': price,\n",
    "            'Volume': volume,\n",
    "            'Sector': sector,\n",
    "        },\n",
    "        screen=QTradableStocksUS()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline is run over this time range and outputs a dataframe indexed by asset name:\n",
    "START_DATE = '2003'\n",
    "END_DATE = '2018-01-01'\n",
    "\n",
    "start = time.time()\n",
    "QTU_pipeline = run_pipeline(make_pipeline(), START_DATE, END_DATE, chunksize=252)\n",
    "print 'Took %s seconds' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display constituent stocks of QTradableStocksUS:\n",
    "QTU_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The QTradableStocksUS universe generally contains a greater number of assets than previous iterations of the tradable universe.\n",
    "## The resulting summary table displays the mean, std, min-max of daily median in addition to number of assets in this universe:\n",
    "daily_constituent_count = QTU_pipeline.groupby(level=0).sum()\n",
    "QTU_pipeline.groupby(level=0).median().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Displays the number of assets in universe every day, which mirrors major economic events throughout the time period.\n",
    "dates = QTU_pipeline.index.levels[0]\n",
    "grouped = QTU_pipeline.groupby(level=0).count()\n",
    "num_securities = grouped['AverageDollarVolume200'].values\n",
    "plt.plot(dates, num_securities)\n",
    "plt.title('Number of securities in tradeable universe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of assets in universe broken down by sector type:\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'orange', 'gray', 'maroon', 'olive', 'navy']\n",
    "\n",
    "for (sector, name), color in zip(Sector.SECTOR_NAMES.iteritems(), colors):\n",
    "    sector_result = QTU_pipeline.loc[QTU_pipeline['Sector'] == sector]\n",
    "    grouped = sector_result.groupby(level=0).count()\n",
    "    num_securities = grouped['AverageDollarVolume200'].values\n",
    "    plt.plot(dates, num_securities, label=name, color=color)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.3, 1))\n",
    "plt.title('Number of securities per sector in tradeable universe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Added and Removed Assets\n",
    "#Number of assets added to universe is usually slightly greater than number of assets removed from universe.\n",
    "\n",
    "assets_each_day = [set(df.loc[date].index) for date, df in QTU_pipeline.groupby(level=0)]\n",
    "a = []\n",
    "for i in range(1, len(assets_each_day)):\n",
    "    a.append(assets_each_day[i] - assets_each_day[i-1])\n",
    "\n",
    "#Record the number of new assets to universe each day:\n",
    "new_assets_each_day = pd.Series(a, dates[1:])\n",
    "num_new_assets_each_day = new_assets_each_day.apply(lambda x: len(x))\n",
    "\n",
    "b = []\n",
    "for i in range(1, len(assets_each_day)):\n",
    "    b.append(assets_each_day[i-1] - assets_each_day[i])\n",
    "\n",
    "#Record the number of assets removed from universe each day:\n",
    "removed_assets_each_day = pd.Series(b, dates[1:])\n",
    "num_removed_assets_each_day = removed_assets_each_day.apply(lambda x: len(x))\n",
    "\n",
    "plt.plot(num_new_assets_each_day)\n",
    "plt.title('Number of new securities per day in tradeable universe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(num_removed_assets_each_day)\n",
    "plt.title('Number of removed securities per day in tradeable universe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Scraping Google News API for Investor Sentiment\n",
    "\n",
    "The project will utilize Scrapy and Google News API to capture articles about stocks in the QTradableStocksUS universe to be used in sentiment analysis techniques. \n",
    "\n",
    "### Do I need to use Scrapy at all? Newsapi may be sufficient by itself.\n",
    "### I can take the description from each article, store it in a DataFrame, then run sentiment analysis on each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import json\n",
    "import requests\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "api = NewsApiClient(api_key='2613ce5e838a464b814b7d5b4c2e6bf8')\n",
    "\n",
    "# TODO: Make a DF of Date, Stock, Article_Source, Article_Description, LDA_Result\n",
    "\n",
    "stocks_list = []\n",
    "stocks_list.append(QTradableStocksUS[0])\n",
    "# For each stock, crawl the google news api for relevant articles for each day\n",
    "For stock in stocks_list:\n",
    "    all_articles = newsapi.get_everything(q= str([stock]),\n",
    "                                      #sources='bbc-news,the-verge',\n",
    "                                      #domains='bbc.co.uk,techcrunch.com',\n",
    "                                      #START_DATE and END_DATE were declared when making the pipeline\n",
    "                                      from_parameter= START_DATE,\n",
    "                                      to= END_DATE,\n",
    "                                      language='en')\n",
    "                                      #,sort_by='relevancy'\n",
    "                                      # Only a limited number are shown at a time though, so use the page \n",
    "                                      # parameter in your requests to page through them.\n",
    "                                      #,page=2)\n",
    "\n",
    "\n",
    "# TODO: Extract the date, source url, and description\n",
    "    For article in response.articles: \n",
    "        # Append date, source url, and description to the DF created above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://newsapi.org/v2/everything?q=bitcoin&apiKey=API_KEY\\n{\\n\"status\": \"ok\",\\n\"totalResults\": 46339,\\n-\"articles\": [\\n-{\\n-\"source\": {\\n\"id\": null,\\n\"name\": \"Cointelegraph.com\"\\n},\\n\"author\": \"CoinTelegraph By Darryn Pollock\",\\n\"title\": \"Bitcoin-Related Jobs Booming Along With Bitcoin\",\\n\"description\": \"With an 82 percent growth in the third quarter, Bitcoin-related jobs are the fastest growing category, according to employment website Freelancer.\",\\n\"url\": \"https://cointelegraph.com/news/bitcoin-related-jobs-booming-along-with-bitcoin\",\\n\"urlToImage\": \"https://cointelegraph.com/images/725_Ly9jb2ludGVsZWdyYXBoLmNvbS9zdG9yYWdlL3VwbG9hZHMvdmlldy80MDY5YWQ5MmQxNTU4YWIyYTdhYTg0MTIxM2QwM2M5Zi5qcGc=.jpg\",\\n\"publishedAt\": \"2017-10-31T08:43:21Z\"\\n}\\n]\\n}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example response from Google News API\n",
    "'''\n",
    "https://newsapi.org/v2/everything?q=bitcoin&apiKey=API_KEY\n",
    "{\n",
    "\"status\": \"ok\",\n",
    "\"totalResults\": 46339,\n",
    "-\"articles\": [\n",
    "-{\n",
    "-\"source\": {\n",
    "\"id\": null,\n",
    "\"name\": \"Cointelegraph.com\"\n",
    "},\n",
    "\"author\": \"CoinTelegraph By Darryn Pollock\",\n",
    "\"title\": \"Bitcoin-Related Jobs Booming Along With Bitcoin\",\n",
    "\"description\": \"With an 82 percent growth in the third quarter, Bitcoin-related jobs are the fastest growing category, according to employment website Freelancer.\",\n",
    "\"url\": \"https://cointelegraph.com/news/bitcoin-related-jobs-booming-along-with-bitcoin\",\n",
    "\"urlToImage\": \"https://cointelegraph.com/images/725_Ly9jb2ludGVsZWdyYXBoLmNvbS9zdG9yYWdlL3VwbG9hZHMvdmlldy80MDY5YWQ5MmQxNTU4YWIyYTdhYTg0MTIxM2QwM2M5Zi5qcGc=.jpg\",\n",
    "\"publishedAt\": \"2017-10-31T08:43:21Z\"\n",
    "}\n",
    "]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "****************************************************************************************\n",
    "#Might not need this\n",
    "\n",
    "\n",
    "#Build a crawler to crawl Google's top news articles and pull articles containing any mentions of a stock from QTradableStocksUS\n",
    "class GoogleSpider(scrapy.Spider):\n",
    "    name = \"GS\"\n",
    "    \n",
    "    allowed_domains = ['newsapi.org']\n",
    "    \n",
    "    \n",
    "    # Here is where we insert our API call to get Google news articles related to bitcoin.\n",
    "    start_urls = ['https://newsapi.org/v2/everything?q=bitcoin&apiKey=2613ce5e838a464b814b7d5b4c2e6bf8'\n",
    "                 ,'https://newsapi.org/v2/everything?q=ethereum&apiKey=2613ce5e838a464b814b7d5b4c2e6bf8']\n",
    "      \n",
    "    # Identifying the information we want from the query response and extracting it using xpath.\n",
    "    def parse(self, response):\n",
    "        data = json.loads(response.body_as_unicode())\n",
    "        data2 = []\n",
    "        for article in data['articles']:\n",
    "            yield {\n",
    "                'url' : article['url']\n",
    "            }\n",
    "                \n",
    "\n",
    "process = CrawlerProcess({\n",
    "    'FEED_FORMAT': 'json',\n",
    "    'FEED_URI': 'GoogleLinks5.json',\n",
    "    # Note that because we are doing API queries, the robots.txt file doesn't apply to us.\n",
    "    'ROBOTSTXT_OBEY': False,\n",
    "    'USER_AGENT': 'MatthewGoogleNewsCrawler (makennedy626@gmail.com)',\n",
    "    'AUTOTHROTTLE_ENABLED': True,\n",
    "    'HTTPCACHE_ENABLED': True,\n",
    "    'LOG_ENABLED': False,\n",
    "    # We use CLOSESPIDER_PAGECOUNT to limit our scraper to the first 10 links.    \n",
    "    'CLOSESPIDER_PAGECOUNT' : 10\n",
    "})\n",
    "                                         \n",
    "\n",
    "# Starting the crawler with our spider.\n",
    "process.crawl(GoogleSpider)\n",
    "process.start()\n",
    "print('First 100 links extracted!')\n",
    "\n",
    "***********************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Unsupervised Machine Learning on Scraped Data for Sentiment Analysis\n",
    "\n",
    "### Methods for Unsupervised Sentiment Analysis:\n",
    "#### Latent Dirichlet Allocation (LDA): https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "#### LDA with Gensim: https://en.wikipedia.org/wiki/Gensim\n",
    "#### LDA with Spark: https://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Supervised Machine Learning to Generate Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XII. Important Information from Quantopian's Contest Page\n",
    "\n",
    "### Process\n",
    "\n",
    "A new contest is started at the beginning of each month. Contest entries are paper traded for 6 months. At the end of the 6 months, the winner is announced.\n",
    "\n",
    "While the Quantopian Open is limited to one winner per month, our allocations are not. We want dozens of algorithms, and anyone meeting the low beta and consistent-returns filters is well-positioned for those rewards.\n",
    "\n",
    "It is a rolling competition. All entries are automatically entered in every subsequent contest, unless withdrawn.\n",
    "\n",
    "If you win, the overall performance of your algorithm during the prize period will be public - other people will want to see how you are doing!\n",
    "\n",
    "### Judging\n",
    "\n",
    "Your algorithm's performance must have low correlation to the general market's performance. This correlation is calculated as the beta-to-SPY, and it must be between 0.3 and -0.3. The algorithms that meet this requirement are placed at the top of the leaderboard and are marked with a badge.\n",
    "\n",
    "Your algorithm must be hedged. It should hold both long and short positions simultaneously, or be entirely in cash. Hedged strategies reduce their market risk and correlation risk to individual positions. These algorithms are placed at the top of the leaderboard and are marked with a badge.\n",
    "\n",
    "Your algorithm must have positive returns. It must make trades in both paper trading and backtesting. Algorithms meeting this criterion also are placed at the top of the leaderboard and are marked with a badge.\n",
    "\n",
    "To generate your algorithm's score, its live trading performance is ranked against all of the other entries on the 7 criteria listed below. The ranks are averaged and scored on a scale of 0 to 100. Your score is quite volatile in the days immediately after you make your entry, and your score smooths out as your entry runs for a longer time period.\n",
    "\n",
    "The best way to evaluate your algorithm is to use our backtest analysis tool to generate a 'tear sheet.' The tear sheet is chock-full of staticstics and comparisons to help you evaluate your algorithm's performance. It's the same tool that we use at Quantopian to evaluate algorithms for allocation.\n",
    "\n",
    "These criteria were picked to encourage algorithm creation that matches our allocation interests.\n",
    "\n",
    "#### Sharpe Ratio: The gold standard of performance metrics. Penalizes an algorithm if it takes excessive risk to achieve its return. Higher Sharpe is better.\n",
    "\n",
    "#### Annualized volatility: Lower volatility is better.\n",
    "\n",
    "#### Annualized returns: The algorithm has to make money.\n",
    "\n",
    "#### Max Drawdown: The greatest loss suffered from a peak in equity to its subsequent trough. By minimizing drawdown, Participant's algorithm can better compound gains.\n",
    "\n",
    "#### Stability of Return: This measures how consistently an algorithm generates its profits over time. (Mathematically, the R-squared of the linear regression line drawn through the algorithm's equity curve based on log-returns).\n",
    "\n",
    "#### Sortino Ratio: Annual Return / standard deviation of negative returns. This is a quick way to compare across algorithms how long it might take to get back above its high-water mark after suffering a loss equal to its historical max drawdown. A large Sortino ratio indicates a low probability of a large loss.\n",
    "\n",
    "#### Beta-to-SPY: How connected your algorithm is to swings in the value of SPY.\n",
    "\n",
    "### Important Rules \n",
    "\n",
    "Your algorithm must keep its leverage under three. If your leverage exceeds three, in backtest or paper trading, your entry will be disqualified. You can track your leverage using context.account.leverage.\n",
    "\n",
    "Your algorithm must use the default commission model. We will assign a custom slippage model of $0.001/share for judging. If you would like to test your algorithm with this commission model, you can use set_commission(commission.PerShare(cost=0.001, min_trade_cost=0)).\n",
    "\n",
    "Your algorithm can't use fetcher. The Participant's algorithm must not use the fetch_csv() feature. (If you have a data source or signal that you think should be available for the contest, please tell us about it at feedback@quantopian.com)\n",
    "\n",
    "Your algorithm can't trade leveraged ETFs or ETNs. The Participant's algorithm must not trade in leveraged ETFs, such as the Ultra S&P500 or Ultra Dow30. To avoid trading these assets, use the set_do_not_order() trading guard. You can also use the QTradableStocksUS, which doesn't contain any ETFs, as your base universe.\n",
    "\n",
    "If your algorithm crashes, your entry will be disqualified.\n",
    "\n",
    "Each person is limited to three entries. If you want to enter a fourth time, you will need to stop one of your existing entries to make room.\n",
    "\n",
    "There is no fee for entry. You can read the full set of contest rules here. https://www.quantopian.com/open/rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
